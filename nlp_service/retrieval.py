"""FAISS-based Retrieval System (fixed async init)"""
import os
from typing import List, Dict, Any, Tuple
import numpy as np
import faiss
import json
from .embedding_service import get_embedding_service
from .config import nlp_config
import structlog

logger = structlog.get_logger()


class Document:
    """Document with metadata"""
    def __init__(self, text: str, metadata: Dict[str, Any]):
        self.text = text
        self.metadata = metadata

    def to_dict(self) -> Dict[str, Any]:
        return {"text": self.text, "metadata": self.metadata}

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "Document":
        return cls(data["text"], data["metadata"])


class RetrievalSystem:
    """
    FAISS-based semantic retrieval system.

    Important fix:
    - build_index() is async, so we MUST NOT call it inside __init__ / _initialize().
    - Instead, we call it from get_retrieval_system() where we can await.
    """

    def __init__(self):
        self.config = nlp_config
        self.embedding_service = get_embedding_service()
        self.index = None
        self.documents: List[Document] = []
        self._initialize()

    def _initialize(self):
        """
        Initialize or load FAISS index.

        MVP behavior:
        - If an index exists on disk -> load it (sync).
        - Else -> create default documents (sync), and let async build happen later.
        """
        try:
            index_file = f"{self.config.faiss_index_path}.index"
            docs_file = f"{self.config.faiss_index_path}.docs.json"

            if os.path.exists(index_file) and os.path.exists(docs_file):
                self.load_index()
            else:
                logger.info("Creating new FAISS index (documents only; index will build asynchronously)")
                self._create_default_documents()

                # Create an empty index placeholder (so search won't crash)
                # Real embeddings will be added when build_index() is awaited.
                self.index = faiss.IndexFlatIP(self.config.faiss_dimension)

        except Exception as e:
            logger.error("Failed to initialize retrieval system", error=str(e))
            # Create empty index as fallback
            self.index = faiss.IndexFlatIP(self.config.faiss_dimension)

    def _create_default_documents(self):
        """Create default knowledge base documents"""
        default_docs = [
            # KPI Explanations
            Document(
                "Traffic index measures the number of customers entering a branch. "
                "It's calculated as the ratio of actual footfall to baseline footfall.",
                {"source": "kpi_docs", "type": "kpi_explanation", "kpi": "traffic"}
            ),
            Document(
                "Sales KPI tracks total revenue generated by a branch. "
                "It includes all transactions and payment methods.",
                {"source": "kpi_docs", "type": "kpi_explanation", "kpi": "sales"}
            ),
            Document(
                "Conversion rate is the percentage of visitors who make a purchase. "
                "Formula: (Number of transactions / Total visitors) Ã— 100",
                {"source": "kpi_docs", "type": "kpi_explanation", "kpi": "conversion"}
            ),
            Document(
                "Dwell time measures average time customers spend in the store. "
                "Longer dwell time often correlates with higher purchase probability.",
                {"source": "kpi_docs", "type": "kpi_explanation", "kpi": "dwell_time"}
            ),
            Document(
                "Basket size represents the average number of items per transaction. "
                "It's a key metric for cross-selling effectiveness.",
                {"source": "kpi_docs", "type": "kpi_explanation", "kpi": "basket_size"}
            ),

            # Business Rules
            Document(
                "Branch performance is evaluated daily against weekly baselines. "
                "Significant deviations (>20%) trigger automatic alerts to managers.",
                {"source": "business_rules", "type": "policy"}
            ),
            Document(
                "Peak hours are typically 11 AM - 2 PM and 5 PM - 8 PM. "
                "Staffing levels should be adjusted accordingly.",
                {"source": "business_rules", "type": "operations"}
            ),
            Document(
                "Promotions are scheduled monthly and must be approved 2 weeks in advance. "
                "All promotions are tracked in the system for effectiveness analysis.",
                {"source": "business_rules", "type": "policy"}
            ),

            # Analytics Documentation
            Document(
                "The analytics system processes data in real-time using computer vision. "
                "Customer counts are updated every 5 minutes with 95% accuracy.",
                {"source": "analytics_docs", "type": "technical"}
            ),
            Document(
                "Historical data is retained for 2 years for trend analysis. "
                "Year-over-year comparisons are available for all KPIs.",
                {"source": "analytics_docs", "type": "technical"}
            ),
            Document(
                "Branch status includes current occupancy, staff on duty, and operational alerts. "
                "Real-time updates are provided through the dashboard.",
                {"source": "analytics_docs", "type": "feature"}
            ),

            # Task Management
            Document(
                "Tasks can be assigned to employees with priority levels: low, medium, high, urgent. "
                "Overdue tasks are highlighted in the system.",
                {"source": "task_docs", "type": "feature"}
            ),
            Document(
                "Common task types include: inventory check, customer service, maintenance, "
                "and administrative duties.",
                {"source": "task_docs", "type": "reference"}
            ),
        ]

        self.documents = default_docs
        logger.info("Created default knowledge base", doc_count=len(default_docs))

    async def build_index(self):
        """Build FAISS index from documents"""
        try:
            if not self.documents:
                logger.warning("No documents to index")
                return

            logger.info("Building FAISS index", doc_count=len(self.documents))

            texts = [doc.text for doc in self.documents]

            # Generate embeddings (async)
            embeddings = await self.embedding_service.encode(texts, normalize=True)

            dimension = embeddings.shape[1]
            self.index = faiss.IndexFlatIP(dimension)
            self.index.add(embeddings.astype("float32"))

            logger.info(
                "FAISS index built successfully",
                doc_count=len(self.documents),
                dimension=dimension
            )

        except Exception as e:
            logger.error("Failed to build FAISS index", error=str(e))
            raise

    async def search(self, query: str, top_k: int = None) -> List[Tuple[Document, float]]:
        """Search for relevant documents"""
        if top_k is None:
            top_k = self.config.faiss_top_k

        try:
            if self.index is None or self.index.ntotal == 0:
                logger.warning("Index is empty")
                return []

            query_embedding = await self.embedding_service.encode_single(query, normalize=True)

            scores, indices = self.index.search(
                query_embedding.reshape(1, -1).astype("float32"),
                min(top_k, self.index.ntotal)
            )

            results = []
            for score, idx in zip(scores[0], indices[0]):
                if idx < len(self.documents):
                    results.append((self.documents[idx], float(score)))

            logger.info("Search completed", query=query, results_count=len(results))
            return results

        except Exception as e:
            logger.error("Search failed", error=str(e), query=query)
            return []

    def save_index(self):
        """Save FAISS index and documents to disk"""
        try:
            index_dir = os.path.dirname(self.config.faiss_index_path)
            if index_dir:
                os.makedirs(index_dir, exist_ok=True)

            faiss.write_index(self.index, f"{self.config.faiss_index_path}.index")

            docs_data = [doc.to_dict() for doc in self.documents]
            with open(f"{self.config.faiss_index_path}.docs.json", "w") as f:
                json.dump(docs_data, f, indent=2)

            logger.info("Index saved", path=self.config.faiss_index_path)

        except Exception as e:
            logger.error("Failed to save index", error=str(e))
            raise

    def load_index(self):
        """Load FAISS index and documents from disk"""
        try:
            self.index = faiss.read_index(f"{self.config.faiss_index_path}.index")

            with open(f"{self.config.faiss_index_path}.docs.json", "r") as f:
                docs_data = json.load(f)
                self.documents = [Document.from_dict(d) for d in docs_data]

            logger.info("Index loaded", path=self.config.faiss_index_path, doc_count=len(self.documents))

        except Exception as e:
            logger.error("Failed to load index", error=str(e))
            raise

    async def add_documents(self, documents: List[Document], rebuild: bool = True):
        """
        Add new documents.

        MVP approach:
        - Append to document list.
        - Rebuild index (simple, but OK for MVP).
        """
        self.documents.extend(documents)
        if rebuild:
            await self.build_index()


# Singleton instance
_retrieval_system = None


async def get_retrieval_system() -> RetrievalSystem:
    """
    Get or create retrieval system singleton.

    We ensure the index is built HERE (async-safe), not inside __init__.
    """
    global _retrieval_system
    if _retrieval_system is None:
        _retrieval_system = RetrievalSystem()

    # If index exists but has no vectors yet, build it now
    if _retrieval_system.index is None or _retrieval_system.index.ntotal == 0:
        await _retrieval_system.build_index()

    return _retrieval_system
