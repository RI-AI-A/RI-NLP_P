# Retail Intelligence NLP Service

Production-grade NLP microservice for a Retail Intelligence Decision Support System. This service provides intent classification, slot filling, query routing, RAG-lite retrieval, and comprehensive guardrails for natural language queries about retail analytics.

## ğŸ¯ Overview

This NLP service is designed to:
- Classify user intents (KPI queries, branch status, tasks, events, promotions, chitchat)
- Extract entities and slots from natural language queries
- Route queries to appropriate backend API endpoints
- Generate explainable responses using RAG-lite (FAISS + Sentence-Transformers)
- Apply safety guardrails (profanity, PII, hallucination detection, confidence thresholding)
- Log all queries and collect user feedback for continuous improvement

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     FastAPI Application                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Routers: /nlp/query | /nlp/logs | /nlp/feedback | /health â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Orchestration Service â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚               â”‚               â”‚
â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
â”‚ Intent  â”‚   â”‚    Slot    â”‚  â”‚  Query   â”‚
â”‚Classifierâ”‚   â”‚   Filling  â”‚  â”‚  Router  â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
     â”‚              â”‚              â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   Guardrails Check  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Response Generator â”‚
         â”‚   (RAG-lite FAISS)  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  PostgreSQL Logging â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“‹ Features

### NLP Capabilities
- **Intent Classification**: LLM-powered (Ollama/OpenAI/Anthropic) with rule-based fallback
- **Slot Filling**: LLM-powered entity extraction with context understanding
- **Query Routing**: Maps intents + slots to REST API endpoints (inc. Situation/Recommendation APIs)
- **RAG-lite Retrieval**: FAISS vector search over knowledge base (KPI docs, business rules, analytics docs)
- **Response Generation**: Natural language generation using LLM with retrieved context

### Safety & Quality
- **Profanity Filter**: Blocks inappropriate language
- **PII Redaction**: Detects and removes emails, phone numbers, SSNs, credit cards
- **Hallucination Detection**: Basic checks for unsupported claims
- **Confidence Thresholding**: Rejects low-confidence predictions
- **Scope Validation**: Ensures queries are within retail domain

### Production Features
- **Structured Logging**: JSON logs with structlog
- **Database Logging**: PostgreSQL with query logs and user feedback
- **Health Checks**: Comprehensive health endpoint
- **API Documentation**: Auto-generated OpenAPI/Swagger docs
- **Database Migrations**: Alembic for schema versioning

## ğŸš€ Quick Start

### Prerequisites
- Python 3.10+
- PostgreSQL 15+
- **Ollama** (for LLM support) - See [OLLAMA_SETUP.md](OLLAMA_SETUP.md)

### Installation & Run

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Download spaCy model
python -m spacy download en_core_web_sm

# Set up Ollama (for LLM support)
# See OLLAMA_SETUP.md for detailed instructions
ollama serve  # In a separate terminal
ollama pull llama3.2:3b

# Set up environment
cp .env.example .env
# Edit .env with your database credentials and LLM settings

# Run database migrations
alembic upgrade head

# Start the service
uvicorn api_service.main:app --host 0.0.0.0 --port 8000 --reload
```

## ğŸ“š API Documentation

### POST /nlp/query

Process a natural language query.

**Request:**
```json
{
  "query": "How busy was branch A yesterday?",
  "conversation_id": "123e4567-e89b-12d3-a456-426614174000",
  "user_role": "manager"
}
```

**Response:**
```json
{
  "intent": "kpi_query",
  "slots": {
    "branch_id": "A",
    "time_range": "yesterday",
    "kpi_type": "traffic"
  },
  "routed_endpoint": "/kpis/branch/A?date=yesterday&kpi_type=traffic",
  "response_text": "I'll retrieve the traffic KPI data for A during yesterday...",
  "confidence": 0.91,
  "sources": ["kpi_docs", "business_rules"]
}
```

### POST /nlp/feedback

Submit user feedback for a query.

**Request:**
```json
{
  "query_id": "123e4567-e89b-12d3-a456-426614174000",
  "rating": 5,
  "comment": "Very helpful response"
}
```

### GET /nlp/logs

Retrieve query logs with filtering.

**Query Parameters:**
- `conversation_id`: Filter by conversation
- `user_role`: Filter by role (manager/analyst/staff)
- `intent`: Filter by intent
- `start_date`: Filter by start date
- `end_date`: Filter by end date
- `limit`: Number of results (default: 100, max: 1000)
- `offset`: Pagination offset

### GET /health

Comprehensive health check.

**Response:**
```json
{
  "status": "healthy",
  "details": {
    "api": "healthy",
    "database": "healthy",
    "intent_classifier": "healthy",
    "retrieval_system": "healthy (13 documents)"
  }
}
```

## ğŸ§ª Testing

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=nlp_service --cov=api_service

# Run specific test file
pytest tests/test_intent_classifier.py -v

# Run specific test
pytest tests/test_query_routing.py::test_kpi_query_routing -v
```

## ğŸ“Š Evaluation

Run offline evaluation on labeled data:

```bash
# Prepare CSV file with columns: query, true_intent, true_slots
# Example: evaluation_data.csv

# Run evaluation
python pipelines/evaluation.py evaluation_data.csv evaluation_report.json
```

**Metrics Calculated:**
- Intent Accuracy
- Slot F1 Score
- Confidence Calibration (ECE)
- Rejection Rate
- Query Resolution Rate

## ğŸ”§ Configuration

### Environment Variables

See `.env.example` for all configuration options:

- **Database**: `DATABASE_URL`, `DATABASE_URL_SYNC`
- **API**: `API_HOST`, `API_PORT`, `API_WORKERS`
- **Models**: `INTENT_MODEL_NAME`, `EMBEDDING_MODEL_NAME`, `SPACY_MODEL`
- **FAISS**: `FAISS_INDEX_PATH`, `FAISS_TOP_K`
- **Thresholds**: `INTENT_CONFIDENCE_THRESHOLD`, `GUARDRAIL_CONFIDENCE_THRESHOLD`
- **Guardrails**: `ENABLE_PROFANITY_FILTER`, `ENABLE_PII_REDACTION`

### Model Configuration

The service supports two modes:

**LLM Mode (Default)**:
- **LLM Provider**: Ollama (local), OpenAI, or Anthropic
- **Default Model**: `llama3.2:3b` (Ollama)
- **Embeddings**: `sentence-transformers/all-MiniLM-L6-v2` (384-dim)
- **Features**: Natural language understanding, context-aware responses

**Rule-Based Mode (Fallback)**:
- **Intent Classification**: `distilbert-base-uncased` or `facebook/bart-large-mnli`
- **NER**: `en_core_web_sm` (spaCy)
- **Response**: Template-based

## ğŸ—„ï¸ Database Schema

### nlp_queries_log
- `id` (UUID, PK)
- `conversation_id` (UUID, indexed)
- `user_role` (String)
- `query_text` (Text)
- `intent` (String, indexed)
- `confidence` (Float)
- `routed_endpoint` (String)
- `created_at` (DateTime, indexed)

### nlp_feedback
- `id` (UUID, PK)
- `query_id` (UUID, FK â†’ nlp_queries_log)
- `rating` (Integer, 1-5)
- `comment` (Text, nullable)
- `created_at` (DateTime)

## ğŸ”„ Integration Contract

This NLP service is designed to integrate with other microservices:

### Input Contract
- Accepts natural language queries via REST API
- Requires conversation_id and user_role for context
- Returns structured JSON with intent, slots, and routing information

### Output Contract
- **Never accesses CV service directly**
- **Only calls backend APIs** via routed endpoints
- **Returns structured + explainable outputs**
- **Can be replaced by LLM later** (same input/output format)

### Downstream Integration
All downstream systems can consume the JSON response:
- `routed_endpoint`: Use this to call the appropriate backend API
- `slots`: Extract parameters for API calls
- `response_text`: Display to user or use for further processing
- `confidence`: Use for filtering or user warnings

## ğŸ“¦ Project Structure

```
retail-intel-nlp-backend/
â”œâ”€â”€ nlp_service/              # Core NLP components
â”‚   â”œâ”€â”€ intent_classifier.py  # BERT-based intent classification
â”‚   â”œâ”€â”€ slot_filling.py       # spaCy NER + regex slot extraction
â”‚   â”œâ”€â”€ query_router.py       # Intent â†’ API endpoint mapping
â”‚   â”œâ”€â”€ embedding_service.py  # Sentence-Transformers embeddings
â”‚   â”œâ”€â”€ retrieval.py          # FAISS vector search
â”‚   â”œâ”€â”€ response_generator.py # RAG-lite response generation
â”‚   â”œâ”€â”€ guardrails.py         # Safety and quality checks
â”‚   â””â”€â”€ config.py             # NLP configuration
â”œâ”€â”€ api_service/              # FastAPI application
â”‚   â”œâ”€â”€ main.py               # FastAPI app setup
â”‚   â”œâ”€â”€ routers/              # API endpoints
â”‚   â”‚   â”œâ”€â”€ nlp.py            # /nlp/query endpoint
â”‚   â”‚   â”œâ”€â”€ queries.py        # /nlp/logs endpoint
â”‚   â”‚   â”œâ”€â”€ feedback.py       # /nlp/feedback endpoint
â”‚   â”‚   â””â”€â”€ health.py         # /health endpoint
â”‚   â”œâ”€â”€ services/             # Business logic
â”‚   â”‚   â”œâ”€â”€ orchestration_service.py  # Main pipeline orchestration
â”‚   â”‚   â”œâ”€â”€ retrieval_service.py      # Retrieval wrapper
â”‚   â”‚   â””â”€â”€ logging_service.py        # Structured logging
â”‚   â”œâ”€â”€ deps.py               # FastAPI dependencies
â”‚   â””â”€â”€ config.py             # API configuration
â”œâ”€â”€ db/                       # Database layer
â”‚   â”œâ”€â”€ base.py               # SQLAlchemy base
â”‚   â”œâ”€â”€ session.py            # Session management
â”‚   â”œâ”€â”€ models.py             # Database models
â”‚   â””â”€â”€ migrations/           # Alembic migrations
â”œâ”€â”€ schemas/                  # Pydantic schemas
â”‚   â”œâ”€â”€ nlp_request.py        # Request schemas
â”‚   â”œâ”€â”€ nlp_response.py       # Response schemas
â”‚   â”œâ”€â”€ feedback.py           # Feedback schemas
â”‚   â””â”€â”€ logs.py               # Log schemas
â”œâ”€â”€ pipelines/                # Offline pipelines
â”‚   â”œâ”€â”€ preprocessing.py      # Text preprocessing
â”‚   â”œâ”€â”€ evaluation.py         # Offline evaluation
â”‚   â””â”€â”€ offline_indexing.py   # FAISS index building
â”œâ”€â”€ tests/                    # Unit tests
â”‚   â”œâ”€â”€ test_intent_classifier.py
â”‚   â””â”€â”€ test_query_routing.py
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ alembic.ini               # Alembic configuration
â”œâ”€â”€ pytest.ini                # Pytest configuration
â”œâ”€â”€ .env.example              # Environment template
â””â”€â”€ README.md                 # This file
```

## ğŸ” Security Considerations

- **PII Protection**: Automatic detection and redaction of sensitive information
- **Input Validation**: Pydantic schemas validate all inputs
- **SQL Injection**: SQLAlchemy ORM prevents SQL injection
- **Rate Limiting**: Can be added via middleware (not included)
- **Authentication**: Placeholder in deps.py for future implementation

## ğŸš§ Future Enhancements

### LLM Replacement Path
This service is designed to be easily replaced by a larger LLM:
1. Keep the same API contract (input/output schemas)
2. Replace orchestration_service.py with LLM calls
3. Use the same guardrails and logging
4. Maintain backward compatibility

### Model Improvements
- Fine-tune BERT on retail-specific data
- Add custom NER model for retail entities
- Implement active learning from user feedback
- Add multi-language support

### Features
- Real-time model updates
- A/B testing framework
- Advanced hallucination detection
- Contextual conversation memory
- Multi-turn dialogue support

## ğŸ“ License

This project is part of a B2B SaaS graduation project.

## ğŸ¤ Contributing

This is an academic project. For questions or suggestions, please contact the project team.

## ğŸ“ Support

For issues or questions:
1. Check the `/health` endpoint for service status
2. Review logs
3. Check database connectivity
4. Verify model downloads completed

## ğŸ“ Academic Context

This NLP service is designed to be:
- **Academically defensible**: Clear architecture, well-documented, testable
- **Modular**: Each component can be tested and replaced independently
- **Production-grade**: Follows best practices for logging, error handling, and monitoring
- **Future-proof**: Easy to replace with LLM while maintaining the same interface

---

**Version**: 1.0.0  
**Last Updated**: 2026-02-08
